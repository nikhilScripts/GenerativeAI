{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNKzaQ8CquUMXddL+j8J7iV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nikhilScripts/GenerativeAI/blob/main/GenerativeAi_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hugging face\n"
      ],
      "metadata": {
        "id": "RTJVZkjcvLOJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install huggingface_hub"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HxaJlXMEvQ1_",
        "outputId": "175c5cf1-b9dd-4dd5-af73-db1d2ce87e65"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (0.28.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (3.17.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (2025.1.31)\n"
          ]
        }
      ]
    },
    {
      "source": [
        "!pip install langchain-community\n",
        "from langchain import HuggingFaceHub"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HI7Ic9yJvz6A",
        "outputId": "370bd17b-8529-4da2-a577-17db5939d220"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.11/dist-packages (0.3.19)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.41 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.45)\n",
            "Requirement already satisfied: langchain<1.0.0,>=0.3.20 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.20)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.39)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.13)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (9.0.0)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.8.1)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.13)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.4.0)\n",
            "Requirement already satisfied: numpy<3,>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.18.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.6 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.20->langchain-community) (0.3.6)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.20->langchain-community) (2.10.6)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.41->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.41->langchain-community) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.41->langchain-community) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.23.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2025.1.31)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.41->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.20->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.20->langchain-community) (2.27.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['mygeminikey'] = ''\n",
        "os.environ['huggin_api'] = ''"
      ],
      "metadata": {
        "id": "MKOLlrGTygnl"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "source": [
        "# https://huggingface.co/google/flan-t5-xl\n",
        "\n",
        "\n",
        "llm = HuggingFaceHub(\n",
        "        repo_id=\"google/flan-t5-large\",\n",
        "        model_kwargs={\"temperature\": 0, \"max_length\": 64},\n",
        "        huggingfacehub_api_token=os.environ.get(\"HUGGINGFACEHUB_API_TOKEN\") # Pass token directly\n",
        "    )\n",
        "\n",
        "llm(\"translate English to German: How old are you?\")"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "collapsed": true,
        "id": "zSBg5qlgwlGd",
        "outputId": "05e5109a-3b48-48c0-f8c5-bc8cf58a0b5f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValidationError",
          "evalue": "1 validation error for HuggingFaceHub\n  Value error, Did not find huggingfacehub_api_token, please add an environment variable `HUGGINGFACEHUB_API_TOKEN` which contains it, or pass `huggingfacehub_api_token` as a named parameter. [type=value_error, input_value={'repo_id': 'google/flan-...nt': None, 'task': None}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.10/v/value_error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-2a9524856a60>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"YOUR_HUGGING_FACE_API_TOKEN\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m llm = HuggingFaceHub(\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mrepo_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"google/flan-t5-large\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"temperature\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"max_length\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/_api/deprecation.py\u001b[0m in \u001b[0;36mwarn_if_direct_instance\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    212\u001b[0m                         \u001b[0mwarned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m                         \u001b[0memit_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m                 obj.__init__ = functools.wraps(obj.__init__)(  # type: ignore[misc]\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/load/serializable.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0;34m\"\"\"\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pydantic/main.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, **data)\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0;31m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0m__tracebackhide__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m         \u001b[0mvalidated_self\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__pydantic_validator__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself_instance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvalidated_self\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m             warnings.warn(\n",
            "\u001b[0;31mValidationError\u001b[0m: 1 validation error for HuggingFaceHub\n  Value error, Did not find huggingfacehub_api_token, please add an environment variable `HUGGINGFACEHUB_API_TOKEN` which contains it, or pass `huggingfacehub_api_token` as a named parameter. [type=value_error, input_value={'repo_id': 'google/flan-...nt': None, 'task': None}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.10/v/value_error"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm = HuggingFaceHub(repo_id=\"google/flan-t5-large\", model_kwargs={\"temperature\":0, \"max_length\":64})\n",
        "name = llm.predict(\"I want to open a restaurant for Chinese food. Suggest a fency name for this.\")\n",
        "print(name)"
      ],
      "metadata": {
        "id": "-o1cklDMwQsV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LangChain memory"
      ],
      "metadata": {
        "id": "N9sCurY30XW5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setting gemini"
      ],
      "metadata": {
        "id": "4Bza0nmo2OjD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mygeminikey = \"AIzaSyCIc9sb7NLCJDM4KlHZERzUdb4C-0ELM6E\""
      ],
      "metadata": {
        "id": "uaUnI1CD2sM8"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "genai.configure(api_key = mygeminikey)\n",
        "model = genai.GenerativeModel('gemini-2.0-flash')"
      ],
      "metadata": {
        "id": "a7nkdZfH2TJj"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = 'explain langchain memory'"
      ],
      "metadata": {
        "id": "W3o2NqMf2_iR"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.generate_content(prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "T0Uztjhv3JcD",
        "outputId": "d307a628-b313-4a37-e851-caf76ddbd8a6"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "response:\n",
              "GenerateContentResponse(\n",
              "    done=True,\n",
              "    iterator=None,\n",
              "    result=protos.GenerateContentResponse({\n",
              "      \"candidates\": [\n",
              "        {\n",
              "          \"content\": {\n",
              "            \"parts\": [\n",
              "              {\n",
              "                \"text\": \"Langchain Memory is a crucial component of the Langchain framework that allows language models (LLMs) to maintain context and state across multiple interactions within a conversation.  Without memory, an LLM treats each interaction as independent, forgetting the previous turns. Memory bridges this gap by storing and retrieving information from past interactions, enabling more coherent, relevant, and engaging conversations.\\n\\nHere's a breakdown of Langchain Memory:\\n\\n**Why is Memory Important?**\\n\\n* **Context Retention:** LLMs are stateless by default. Memory allows them to remember previous user inputs, bot outputs, and even external information injected into the conversation.\\n* **Consistent Dialogue:** Enables consistent personality, tone, and knowledge across multiple turns.\\n* **Personalization:** Can store user preferences, history, and other personal details for a tailored experience.\\n* **Complex Tasks:**  Allows for multi-step reasoning and problem-solving by remembering intermediate steps and results.\\n* **Longer Conversations:**  Makes it possible to maintain coherence in extended dialogues that exceed the model's context window.\\n\\n**How Langchain Memory Works:**\\n\\nLangchain provides a variety of memory modules (classes) that differ in how they store and retrieve information. The core principle is that each memory module:\\n\\n1. **Receives new inputs (user messages, agent actions, etc.).**\\n2. **Updates its internal state (the memory itself).**\\n3. **Provides relevant context to the LLM before the next prompt is sent.**\\n\\n**Key Types of Memory in Langchain:**\\n\\nLangchain offers several built-in memory types, each suited for different use cases:\\n\\n* **`ConversationBufferMemory`:**  Simple memory that stores all conversation turns (input and output) in a buffer (typically a list).  It provides the complete history as context to the LLM. Good for short conversations where the entire history is relevant.  Can become inefficient for longer conversations due to the LLM's context window limitations.\\n\\n   ```python\\n   from langchain.memory import ConversationBufferMemory\\n   from langchain.llms import OpenAI\\n   from langchain.chains import ConversationChain\\n\\n   memory = ConversationBufferMemory()\\n   llm = OpenAI(temperature=0)\\n   conversation = ConversationChain(\\n       llm=llm,\\n       memory=memory,\\n       verbose=True  # Prints out the prompts and responses\\n   )\\n\\n   print(conversation.predict(input=\\\"Hi, I'm Bob.\\\"))\\n   print(conversation.predict(input=\\\"What's my name?\\\")) # Knows the name from previous turn\\n   ```\\n\\n* **`ConversationBufferWindowMemory`:** Stores a sliding window of recent conversation turns.  Only the last `k` interactions are kept in memory.  Useful when you only need recent context and want to manage the memory size.\\n\\n   ```python\\n   from langchain.memory import ConversationBufferWindowMemory\\n   from langchain.llms import OpenAI\\n   from langchain.chains import ConversationChain\\n\\n   memory = ConversationBufferWindowMemory(k=2) # Keep the last 2 interactions\\n   llm = OpenAI(temperature=0)\\n   conversation = ConversationChain(\\n       llm=llm,\\n       memory=memory,\\n       verbose=True\\n   )\\n   print(conversation.predict(input=\\\"My favorite color is blue.\\\"))\\n   print(conversation.predict(input=\\\"What is my favorite color?\\\"))\\n   print(conversation.predict(input=\\\"What was the first thing I told you?\\\")) # Forgets the earlier interaction\\n   ```\\n\\n* **`ConversationSummaryMemory`:** Uses an LLM to summarize the conversation periodically.  Stores the summary instead of the entire history.  This allows for long-term memory while keeping the context size manageable. More complex to implement and can lose some detail in the summaries.\\n\\n   ```python\\n   from langchain.memory import ConversationSummaryMemory\\n   from langchain.llms import OpenAI\\n   from langchain.chains import ConversationChain\\n\\n   memory = ConversationSummaryMemory(llm=OpenAI(temperature=0))\\n   conversation = ConversationChain(\\n       llm=OpenAI(temperature=0),\\n       memory=memory,\\n       verbose=True\\n   )\\n\\n   print(conversation.predict(input=\\\"My name is Alice, and I like to travel.\\\"))\\n   print(conversation.predict(input=\\\"What do you know about me?\\\")) # Provides a summarized description\\n   ```\\n\\n* **`ConversationSummaryBufferMemory`:** Combines the buffer and summarization approaches.  It keeps a buffer of recent conversation turns and periodically summarizes the older parts. Provides a balance between detail and context length.\\n\\n   ```python\\n   from langchain.memory import ConversationSummaryBufferMemory\\n   from langchain.llms import OpenAI\\n   from langchain.chains import ConversationChain\\n\\n   memory = ConversationSummaryBufferMemory(llm=OpenAI(temperature=0), max_token_limit=50) # Summarizes when token limit is reached\\n   conversation = ConversationChain(\\n       llm=OpenAI(temperature=0),\\n       memory=memory,\\n       verbose=True\\n   )\\n\\n   print(conversation.predict(input=\\\"I'm a software engineer who enjoys building web applications with Python and JavaScript.\\\"))\\n   print(conversation.predict(input=\\\"I live in San Francisco and love exploring the city's diverse neighborhoods.\\\"))\\n   print(conversation.predict(input=\\\"What can you tell me about myself based on our conversation?\\\")) # provides a summarized version.\\n   ```\\n\\n* **`ConversationTokenBufferMemory`:** Stores conversation turns in a buffer, but instead of limiting by the number of turns, it limits by the number of tokens. This is useful when dealing with LLMs with token-based pricing or context length limitations.\\n\\n* **`ConversationKnowledgeGraphMemory`:** Uses a knowledge graph to store entities and relationships extracted from the conversation. Enables more structured memory and allows for reasoning based on relationships between concepts. More computationally expensive and requires more advanced setup.\\n\\n* **`VectorStoreRetrieverMemory`:** Indexes conversation history into a vector store (like ChromaDB or FAISS) and retrieves relevant parts based on semantic similarity to the current input. Useful for very long conversations or when context is highly dependent on specific topics.  Requires setting up a vector store.\\n\\n* **`Entity Memory`**:  Tracks information about specific entities within a conversation.  You tell the memory what entities to track, and it maintains a record of their attributes. This is especially useful when you have recurring characters, places, or concepts in your conversation.\\n\\n**Integrating Memory with Langchain Chains:**\\n\\nMemory modules are typically integrated into Langchain chains, such as `ConversationChain`, `RetrievalQAChain`, or custom chains.  The chain handles the interaction with the LLM, while the memory module handles the storage and retrieval of context.  The `memory` parameter in the chain is where you specify the memory module.\\n\\n**Example with `ConversationChain` (Revisited):**\\n\\n```python\\nfrom langchain.memory import ConversationBufferMemory\\nfrom langchain.llms import OpenAI\\nfrom langchain.chains import ConversationChain\\n\\nmemory = ConversationBufferMemory()  # Initialize memory\\nllm = OpenAI(temperature=0)\\n\\nconversation = ConversationChain(\\n    llm=llm,\\n    memory=memory,  # Pass the memory to the chain\\n    verbose=True  # Prints out the prompts and responses\\n)\\n\\nprint(conversation.predict(input=\\\"Hi, I'm Bob.\\\"))\\nprint(conversation.predict(input=\\\"What's my name?\\\")) # The LLM remembers the name!\\nprint(conversation.predict(input=\\\"What do you like to do, Bob?\\\"))\\nprint(conversation.predict(input=\\\"You forgot to ask me what my hobbies are.\\\"))\\n\\n```\\n\\n**Key Considerations when Choosing a Memory Type:**\\n\\n* **Conversation Length:** For short conversations, `ConversationBufferMemory` or `ConversationBufferWindowMemory` may suffice.  For longer conversations, `ConversationSummaryMemory`, `ConversationSummaryBufferMemory`, `ConversationTokenBufferMemory`, or `VectorStoreRetrieverMemory` are more appropriate.\\n* **Context Relevance:** If context is highly localized (only recent history matters), windowed memory is good.  If context can be relevant from any point in the conversation, summarization or vector-based retrieval are better.\\n* **Memory Size:** Consider the limitations of the LLM's context window and the computational cost of storing and processing the memory.\\n* **Structure of Information:** If you need to track specific entities or relationships, `ConversationKnowledgeGraphMemory` or `Entity Memory` might be useful.\\n* **Performance:** Summarization and vector retrieval can be computationally expensive, especially for real-time applications.\\n\\n**In summary, Langchain memory is a critical component for building conversational AI applications that are coherent, engaging, and able to maintain context over multiple turns. Choosing the right memory type depends on the specific requirements of your application and the characteristics of your conversation data.**\\n\"\n",
              "              }\n",
              "            ],\n",
              "            \"role\": \"model\"\n",
              "          },\n",
              "          \"finish_reason\": \"STOP\",\n",
              "          \"citation_metadata\": {\n",
              "            \"citation_sources\": [\n",
              "              {\n",
              "                \"start_index\": 2038,\n",
              "                \"end_index\": 2183,\n",
              "                \"uri\": \"https://medium.com/feed/@rayspark-jp\"\n",
              "              },\n",
              "              {\n",
              "                \"start_index\": 2785,\n",
              "                \"end_index\": 2926,\n",
              "                \"uri\": \"https://github.com/langchain-ai/langchain/issues/13696\"\n",
              "              },\n",
              "              {\n",
              "                \"start_index\": 2848,\n",
              "                \"end_index\": 2977,\n",
              "                \"uri\": \"https://github.com/deva-ghb/cgpt-finetune\"\n",
              "              },\n",
              "              {\n",
              "                \"start_index\": 4474,\n",
              "                \"end_index\": 4615,\n",
              "                \"uri\": \"https://github.com/CielZ001/Chatbot\"\n",
              "              },\n",
              "              {\n",
              "                \"start_index\": 6856,\n",
              "                \"end_index\": 6992,\n",
              "                \"uri\": \"https://medium.com/feed/@rayspark-jp\"\n",
              "              }\n",
              "            ]\n",
              "          },\n",
              "          \"avg_logprobs\": -0.3867678711956876\n",
              "        }\n",
              "      ],\n",
              "      \"usage_metadata\": {\n",
              "        \"prompt_token_count\": 4,\n",
              "        \"candidates_token_count\": 1916,\n",
              "        \"total_token_count\": 1920\n",
              "      },\n",
              "      \"model_version\": \"gemini-2.0-flash\"\n",
              "    }),\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Memory"
      ],
      "metadata": {
        "id": "79OIfIf_8GdW"
      }
    },
    {
      "source": [
        "!pip install langchain-google-genai # install the necessary package\n",
        "\n",
        "import google.generativeai as genai\n",
        "from langchain import LLMChain, PromptTemplate\n",
        "from langchain_google_genai.llms import GoogleGenerativeAI"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yq2SGiz35ygS",
        "outputId": "dd66c1a0-345b-4ab5-ad4b-2093ec211d62"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain-google-genai in /usr/local/lib/python3.11/dist-packages (2.1.0)\n",
            "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from langchain-google-genai) (1.2.0)\n",
            "Requirement already satisfied: google-ai-generativelanguage<0.7.0,>=0.6.16 in /usr/local/lib/python3.11/dist-packages (from langchain-google-genai) (0.6.17)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.43 in /usr/local/lib/python3.11/dist-packages (from langchain-google-genai) (0.3.45)\n",
            "Requirement already satisfied: pydantic<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-google-genai) (2.10.6)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (2.24.2)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (2.38.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (1.26.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (4.25.6)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.43->langchain-google-genai) (0.3.13)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.43->langchain-google-genai) (9.0.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.43->langchain-google-genai) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.43->langchain-google-genai) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.43->langchain-google-genai) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.43->langchain-google-genai) (4.12.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2->langchain-google-genai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2->langchain-google-genai) (2.27.2)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (1.69.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (2.32.3)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (1.71.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (1.62.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (4.9)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.43->langchain-google-genai) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.43->langchain-google-genai) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.43->langchain-google-genai) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.43->langchain-google-genai) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.43->langchain-google-genai) (0.23.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.43->langchain-google-genai) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.43->langchain-google-genai) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.43->langchain-google-genai) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.43->langchain-google-genai) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.43->langchain-google-genai) (0.14.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (2.3.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.43->langchain-google-genai) (1.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Authentication**"
      ],
      "metadata": {
        "id": "uxG82Yio9_oM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "#  directly access the mygeminikey variable\n",
        "GOOGLE_API_KEY = mygeminikey  #  'mygeminikey' holds your API key\n",
        "\n",
        "os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY"
      ],
      "metadata": {
        "id": "WjbTJ8W28pkY"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = GoogleGenerativeAI(model = 'gemini-2.0-flash')"
      ],
      "metadata": {
        "id": "iGUGNBjo6Tjq"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tbagZWh07mPo",
        "outputId": "3d3d7900-5ba8-4c04-8a24-ea3424c083fc"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GoogleGenerativeAI(model='gemini-2.0-flash', google_api_key=SecretStr('**********'), client=ChatGoogleGenerativeAI(model='models/gemini-2.0-flash', google_api_key=SecretStr('**********'), client=<google.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient object at 0x7ae0dc0eefd0>, default_metadata=()))"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template_name = PromptTemplate(\n",
        "    input_variables =['product'],\n",
        "    template = \"What is a good name for a company that makes {product} give just one name\"\n",
        ")"
      ],
      "metadata": {
        "id": "8ovdiys_4EX6"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = LLMChain(llm = llm ,prompt=prompt_template_name)\n",
        "name = chain.run(\"colorful socks\")\n",
        "print(name.strip())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ve2DaH6z4aup",
        "outputId": "f9664548-5cc5-4bbc-8c77-c01f5effe0c7"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SockSpectra\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template_name = PromptTemplate(\n",
        "    input_variables =['product'],\n",
        "    template = \"What would be  a good name for a company that makes {product} give just one name\"\n",
        ")"
      ],
      "metadata": {
        "id": "JeFFptgS9CCs"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "name = chain.run('security cameras')\n",
        "print(name.strip())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-PcrHs979inM",
        "outputId": "19e2cf70-6b13-4ad6-e68a-fa78027de5ad"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentinel\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain.memory"
      ],
      "metadata": {
        "id": "J1lxaYBN97RR"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(chain.memory)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wfrbk1im-Udl",
        "outputId": "ce609d97-36a4-44e8-f010-7e4ad0b362ad"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NoneType"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Conversation Buffer Memory"
      ],
      "metadata": {
        "id": "aovCnaSC-W-1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.memory import ConversationBufferMemory as cbm"
      ],
      "metadata": {
        "id": "zVCeKPWa-cWg"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "memory = cbm()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6o2RrZPr_LMc",
        "outputId": "b11eff40-730b-4a12-cb3f-2cc46b920e78"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-48-4c15c594b160>:1: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
            "  memory = cbm()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template_name = PromptTemplate(\n",
        "    input_variables =['product'],\n",
        "    template = \"What is a good name for a company that makes {product} give just one name\"\n",
        ")"
      ],
      "metadata": {
        "id": "ktCkhdZb_SkW"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = LLMChain(llm = llm, prompt = prompt_template_name, memory = memory)"
      ],
      "metadata": {
        "id": "3sd9bGaH_imX"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "name = chain.run('colorful cups').strip()"
      ],
      "metadata": {
        "id": "4dl_niYv_zrk"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "name"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "2FHUXmoM_8Dc",
        "outputId": "966ee625-6e26-4e02-df9f-ac6235bc3263"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Prismcups'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "name = chain.run('drone camera')"
      ],
      "metadata": {
        "id": "CkYOrsYu_9BK"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rrMU2bQsAeQx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}